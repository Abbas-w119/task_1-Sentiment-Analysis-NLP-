{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4749cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083323aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      author                                            content country  \\\n",
      "0  katyperry  Is history repeating itself...?#DONTNORMALIZEH...     NaN   \n",
      "1  katyperry  @barackobama Thank you for your incredible gra...     NaN   \n",
      "2  katyperry                Life goals. https://t.co/XIn1qKMKQl     NaN   \n",
      "3  katyperry            Me right now üôèüèª https://t.co/gW55C1wrwd     NaN   \n",
      "4  katyperry  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...     NaN   \n",
      "\n",
      "          date_time            id language  latitude  longitude  \\\n",
      "0  12/01/2017 19:52  8.196330e+17       en       NaN        NaN   \n",
      "1  11/01/2017 08:38  8.191010e+17       en       NaN        NaN   \n",
      "2  11/01/2017 02:52  8.190140e+17       en       NaN        NaN   \n",
      "3  11/01/2017 02:44  8.190120e+17       en       NaN        NaN   \n",
      "4  10/01/2017 05:22  8.186890e+17       en       NaN        NaN   \n",
      "\n",
      "   number_of_likes  number_of_shares  \n",
      "0             7900              3472  \n",
      "1             3689              1380  \n",
      "2            10341              2387  \n",
      "3            10774              2458  \n",
      "4            17620              4655  \n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\muham\\Downloads\\archive (3)\\tweets.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13048f3a",
   "metadata": {},
   "source": [
    "Cleaning the mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a18e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  \\\n",
      "0  Is history repeating itself...?#DONTNORMALIZEH...   \n",
      "1  @barackobama Thank you for your incredible gra...   \n",
      "2                Life goals. https://t.co/XIn1qKMKQl   \n",
      "3            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
      "4  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
      "\n",
      "                                       clean_content  \n",
      "0  is history repeating itselfdontnormalizehate h...  \n",
      "1  barackobama thank you for your incredible grac...  \n",
      "2                       life goals httpstcoxinqkmkql  \n",
      "3                      me right now  httpstcogwcwrwd  \n",
      "4  sisters are doin it for themselves  httpstcosh...  \n"
     ]
    }
   ],
   "source": [
    "def clean_content(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\",\"\",text)\n",
    "    return text\n",
    "df[\"clean_content\"] = df[\"content\"].apply(clean_content)\n",
    "print(df[[\"content\",\"clean_content\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33fec69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Using cached vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in d:\\Programming\\P\\ML\\Jupyter\\.venv\\Lib\\site-packages (from vaderSentiment) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\Programming\\P\\ML\\Jupyter\\.venv\\Lib\\site-packages (from requests->vaderSentiment) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\Programming\\P\\ML\\Jupyter\\.venv\\Lib\\site-packages (from requests->vaderSentiment) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\Programming\\P\\ML\\Jupyter\\.venv\\Lib\\site-packages (from requests->vaderSentiment) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\Programming\\P\\ML\\Jupyter\\.venv\\Lib\\site-packages (from requests->vaderSentiment) (2026.1.4)\n",
      "Using cached vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb268d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment  sentiment_label\n",
      "0   Neutral                1\n",
      "1  Positive                2\n",
      "2   Neutral                1\n",
      "3   Neutral                1\n",
      "4   Neutral                1\n"
     ]
    }
   ],
   "source": [
    "# Using a pre-trained model and assigning the values to it\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df[\"sentiment_score\"] = df[\"clean_content\"].apply(\n",
    "    lambda x: analyzer.polarity_scores(x)[\"compound\"]\n",
    ")\n",
    "\n",
    "def classify(score):\n",
    "    if score >= 0.5:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.5:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "df[\"sentiment\"] = df[\"sentiment_score\"].apply(classify)\n",
    "\n",
    "df[\"sentiment_label\"] = df[\"sentiment\"].map({\"Positive\":2, \"Neutral\":1, \"Negative\":0})\n",
    "print(df[[\"sentiment\", \"sentiment_label\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a97e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample:  39406\n",
      "Test sample:  13136\n"
     ]
    }
   ],
   "source": [
    "# Splitting data for cleanong and testing \n",
    "\n",
    "X = df[\"clean_content\"]\n",
    "y = df[\"sentiment_label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25,random_state=42)\n",
    "print(\"training sample: \",len(X_train))\n",
    "print(\"Test sample: \",len(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
